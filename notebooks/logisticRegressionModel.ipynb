{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('prepare_data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = \"../datasets/dummyTrain.csv\"\n",
    "\n",
    "custRDD = sc.textFile(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Customer_ID,Name,Gender,Address,Nationality,Account_Type,Age,Education,Employment,Salary,Employer_Stability,Customer_Loyalty,Balance,Residential_Status,Service_Level',\n",
       " u'0,Ashley Payne,Male,1114 Odonnell Camp,Zimbabwean,Current,0,0,1,2,1,1,1,1,1',\n",
       " u'1,Michelle Clark,Female,23560 Ayala Spring,Zimbabwean,Current,0,0,0,2,1,1,2,1,1',\n",
       " u'2,Rodney Rich PhD,Male,883 Franco Knolls,Zimbabwean,Savings,2,1,2,2,0,0,0,0,1',\n",
       " u'3,Janet Hernandez,Male,2440 Strickland Park,Zimbabwean,Savings,0,1,1,1,0,1,0,1,0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the lines on the commas\n",
    "custRDD = custRDD.map(lambda line: line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Customer_ID',\n",
       "  u'Name',\n",
       "  u'Gender',\n",
       "  u'Address',\n",
       "  u'Nationality',\n",
       "  u'Account_Type',\n",
       "  u'Age',\n",
       "  u'Education',\n",
       "  u'Employment',\n",
       "  u'Salary',\n",
       "  u'Employer_Stability',\n",
       "  u'Customer_Loyalty',\n",
       "  u'Balance',\n",
       "  u'Residential_Status',\n",
       "  u'Service_Level'],\n",
       " [u'0',\n",
       "  u'Ashley Payne',\n",
       "  u'Male',\n",
       "  u'1114 Odonnell Camp',\n",
       "  u'Zimbabwean',\n",
       "  u'Current',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stripping the header from the RDD\n",
    "# passing a filter tells Spark to select all RDD member\n",
    "header = custRDD.first()\n",
    "custRDD = custRDD.filter(lambda line:line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'0',\n",
       "  u'Ashley Payne',\n",
       "  u'Male',\n",
       "  u'1114 Odonnell Camp',\n",
       "  u'Zimbabwean',\n",
       "  u'Current',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1'],\n",
       " [u'1',\n",
       "  u'Michelle Clark',\n",
       "  u'Female',\n",
       "  u'23560 Ayala Spring',\n",
       "  u'Zimbabwean',\n",
       "  u'Current',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mapping evry line from the RDD to a row in the DataFrame\n",
    "# piping the result with .toDF() to create the DataFrame\n",
    "\n",
    "df = custRDD.map(lambda line: Row(Age = line[6], Education = line[7], Employment = line[8], Salary = line[9]\n",
    "                                  , Employer_Stability = line[10], Customer_Loyalty = line[11], Balance = line[12]\n",
    "                                  , Residential_Status = line[13], Service_Level = line[14])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Age=u'0', Balance=u'1', Customer_Loyalty=u'1', Education=u'0', Employer_Stability=u'1', Employment=u'1', Residential_Status=u'1', Salary=u'2', Service_Level=u'1'),\n",
       " Row(Age=u'0', Balance=u'2', Customer_Loyalty=u'1', Education=u'0', Employer_Stability=u'1', Employment=u'0', Residential_Status=u'1', Salary=u'2', Service_Level=u'1'),\n",
       " Row(Age=u'2', Balance=u'0', Customer_Loyalty=u'0', Education=u'1', Employer_Stability=u'0', Employment=u'2', Residential_Status=u'0', Salary=u'2', Service_Level=u'1'),\n",
       " Row(Age=u'0', Balance=u'0', Customer_Loyalty=u'1', Education=u'1', Employer_Stability=u'0', Employment=u'1', Residential_Status=u'1', Salary=u'1', Service_Level=u'0'),\n",
       " Row(Age=u'1', Balance=u'0', Customer_Loyalty=u'1', Education=u'1', Employer_Stability=u'1', Employment=u'0', Residential_Status=u'1', Salary=u'2', Service_Level=u'1')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|Service_Level|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|  0|      1|               1|        0|                 1|         1|                 1|     2|            1|\n",
      "|  0|      2|               1|        0|                 1|         0|                 1|     2|            1|\n",
      "|  2|      0|               0|        1|                 0|         2|                 0|     2|            1|\n",
      "|  0|      0|               1|        1|                 0|         1|                 1|     1|            0|\n",
      "|  1|      0|               1|        1|                 1|         0|                 1|     2|            1|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Customer_Loyalty</th>\n",
       "      <th>Education</th>\n",
       "      <th>Employer_Stability</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Residential_Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Service_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Balance Customer_Loyalty Education Employer_Stability Employment  \\\n",
       "0   0       1                1         0                  1          1   \n",
       "1   0       2                1         0                  1          0   \n",
       "2   2       0                0         1                  0          2   \n",
       "3   0       0                1         1                  0          1   \n",
       "4   1       0                1         1                  1          0   \n",
       "\n",
       "  Residential_Status Salary Service_Level  \n",
       "0                  1      2             1  \n",
       "1                  1      2             1  \n",
       "2                  0      2             1  \n",
       "3                  1      1             0  \n",
       "4                  1      2             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_Age = df[df.Age == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|Service_Level|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|  0|      1|               1|        0|                 1|         1|                 1|     2|            1|\n",
      "|  0|      2|               1|        0|                 1|         0|                 1|     2|            1|\n",
      "|  0|      0|               1|        1|                 0|         1|                 1|     1|            0|\n",
      "|  0|      0|               1|        1|                 1|         0|                 0|     1|            0|\n",
      "|  0|      2|               0|        1|                 0|         2|                 1|     1|            1|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "favorite_Age.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|Balance|\n",
      "+---+-------+\n",
      "|  0|      1|\n",
      "|  0|      2|\n",
      "|  2|      0|\n",
      "|  0|      0|\n",
      "|  1|      0|\n",
      "|  0|      0|\n",
      "|  2|      0|\n",
      "|  1|      1|\n",
      "|  2|      0|\n",
      "|  1|      1|\n",
      "+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age','Balance').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Age|count|\n",
      "+---+-----+\n",
      "|  0| 3295|\n",
      "|  1| 3363|\n",
      "|  2| 3342|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|               Age|           Balance|  Customer_Loyalty|         Education|Employer_Stability|        Employment|Residential_Status|            Salary|     Service_Level|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|             10000|             10000|             10000|             10000|             10000|             10000|             10000|             10000|             10000|\n",
      "|   mean|            1.0047|            0.9979|            0.5023|            0.5053|            0.4961|            1.0092|             0.505|            1.0027|            0.4988|\n",
      "| stddev|0.8147050290923954|0.8193672719071882|0.5000197115826506|0.4999969096814193|0.5000097908832372|0.8177910724774535|0.4999999999999998|0.8183884688634094|0.6695098089934411|\n",
      "|    min|                 0|                 0|                 0|                 0|                 0|                 0|                 0|                 0|                 0|\n",
      "|    max|                 2|                 2|                 1|                 1|                 1|                 2|                 1|                 2|                 2|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability', 'Employment', 'Residential_Status', 'Salary', 'Service_Level']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression Model with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.select('Service_Level', 'Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability', 'Employment'\n",
    "              , 'Residential_Status', 'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|     Service_Level|               Age|           Balance|  Customer_Loyalty|         Education|Employer_Stability|        Employment|Residential_Status|            Salary|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|             10000|             10000|             10000|             10000|             10000|             10000|             10000|             10000|             10000|\n",
      "|   mean|            0.4988|            1.0047|            0.9979|            0.5023|            0.5053|            0.4961|            1.0092|             0.505|            1.0027|\n",
      "| stddev|0.6695098089934411|0.8147050290923954|0.8193672719071882|0.5000197115826506|0.4999969096814193|0.5000097908832372|0.8177910724774535|0.4999999999999998|0.8183884688634094|\n",
      "|    min|                 0|                 0|                 0|                 0|                 0|                 0|                 0|                 0|                 0|\n",
      "|    max|                 2|                 2|                 2|                 1|                 1|                 1|                 2|                 1|                 2|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Service_Level', 'Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability', 'Employment'\n",
    "              , 'Residential_Status', 'Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "|Service_Level|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|\n",
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "|            1|  0|      1|               1|        0|                 1|         1|                 1|     2|\n",
      "|            1|  0|      2|               1|        0|                 1|         0|                 1|     2|\n",
      "|            1|  2|      0|               0|        1|                 0|         2|                 0|     2|\n",
      "|            0|  0|      0|               1|        1|                 0|         1|                 1|     1|\n",
      "|            1|  1|      0|               1|        1|                 1|         0|                 1|     2|\n",
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Points and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.0,1.0,1.0,0.0,1.0,1.0,1.0,2.0]),\n",
       " LabeledPoint(1.0, [0.0,2.0,1.0,0.0,1.0,0.0,1.0,2.0]),\n",
       " LabeledPoint(1.0, [2.0,0.0,0.0,1.0,0.0,2.0,0.0,2.0]),\n",
       " LabeledPoint(0.0, [0.0,0.0,1.0,1.0,0.0,1.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,1.0,1.0,1.0,0.0,1.0,2.0]),\n",
       " LabeledPoint(0.0, [0.0,0.0,1.0,1.0,1.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [2.0,0.0,0.0,0.0,0.0,1.0,1.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,0.0,1.0,1.0,1.0,2.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,1.0,0.0,0.0,1.0,1.0,1.0,2.0]),\n",
       " LabeledPoint(1.0, [0.0,2.0,0.0,1.0,0.0,2.0,1.0,1.0]),\n",
       " LabeledPoint(2.0, [2.0,2.0,1.0,0.0,0.0,2.0,1.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,2.0,0.0,0.0,1.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,2.0,0.0,1.0,1.0,0.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,1.0,0.0,1.0,2.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,0.0,0.0,1.0,2.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,0.0,1.0,0.0,2.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,0.0,0.0,1.0,2.0,1.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,1.0,0.0,0.0,1.0,2.0,0.0,2.0]),\n",
       " LabeledPoint(0.0, [0.0,1.0,1.0,1.0,0.0,0.0,0.0,2.0])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created a tuple 'temp' of class/ output and a vector of predictors/ features\n",
    "# called rdd.map on the df to return an RDD of LabeledPoints\n",
    "# parsing the data\n",
    "\n",
    "temp = df.rdd.map(lambda line:LabeledPoint(line[0],[line[1:]]))\n",
    "temp.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the file as a parquet file with LabeledPoints\n",
    "\n",
    "# t0 = time()\n",
    "\n",
    "# temp.saveAsTextFile('../datasets/training')\n",
    "\n",
    "# tt = time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # load data\n",
    "# data = spark.read.format(\"csv\").load('../datasets/training/part-00000')\n",
    "\n",
    "# # making a test/ train split \n",
    "\n",
    "# splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "\n",
    "# trainingSet = splits[0]\n",
    "# testingSet = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # MultiClass Classification using a MultiLayer Perceptron Neural Network\n",
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# # Layers:\n",
    "# # input layers of size 8 (features), two intermediate (hidden) of size 9 and 8\n",
    "# # and output of size 3 (classes)\n",
    "\n",
    "# layers = [8, 9, 8, 3]\n",
    "\n",
    "\n",
    "# # NeuralNet trainer with parameters\n",
    "# trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "\n",
    "# # training the model\n",
    "# t0 = time()\n",
    "\n",
    "# model = trainer.fit(trainingSet)\n",
    "\n",
    "# # compute accuracy on test set\n",
    "# result = model.transform(testingSet)\n",
    "# predictionAndLabels = result.select('prediction', 'label')\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "\n",
    "\n",
    "# tt = time() - t0\n",
    "\n",
    "# print('MultiLayerPerceptron Classifier trained in {} seconds').format(round(tt, 3))\n",
    "# print ('Test set accuracy = ' + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet, testingSet = temp.randomSplit([0.8,0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 2.484 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# # building the model\n",
    "t0 = time()\n",
    "\n",
    "logist_model = LogisticRegressionWithLBFGS.train(trainingSet, iterations=10000, numClasses=3)\n",
    "\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "print('Classifier trained in {} seconds').format(round(tt, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.4892\n"
     ]
    }
   ],
   "source": [
    "# # evaluating the model on training data\n",
    "labelsAndPreds = temp.map(lambda p: (p.label, logist_model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(temp.count())\n",
    "\n",
    "print('Training Error = ' + str(trainErr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 2.484 seconds. test accuracy is 0.5108\n"
     ]
    }
   ],
   "source": [
    "# Testing the accuracy of prediction \n",
    "t0 = time()\n",
    "test_accuracy = labelsAndPreds.filter(lambda (v, p): v == p).count() / float(temp.count())\n",
    "\n",
    "print('Prediction made in {} seconds. test accuracy is {}').format(round(tt, 3), round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load the model\n",
    "lrModel = logist_model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the intercept coefficient\n",
    "logist_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0356, 0.0544, -0.2298, -0.3428, -0.2695, 0.1208, -0.2128, 0.0737, -0.0644, -0.0148, -0.4695, -0.46, -0.4099, -0.047, -0.3341, -0.078])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the weights of the variables\n",
    "logist_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.0,2.0,0.0,1.0,0.0,2.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,2.0,0.0,0.0,1.0,0.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,2.0,1.0,0.0,1.0,2.0,0.0,2.0]),\n",
       " LabeledPoint(2.0, [0.0,2.0,0.0,1.0,1.0,2.0,1.0,2.0]),\n",
       " LabeledPoint(0.0, [2.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,2.0,1.0,0.0,1.0,0.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,1.0,0.0,1.0,2.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,2.0,0.0,1.0,1.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [1.0,1.0,1.0,1.0,0.0,0.0,0.0,2.0]),\n",
       " LabeledPoint(0.0, [1.0,0.0,1.0,0.0,0.0,1.0,1.0,1.0])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine testingSet and predicting\n",
    "testingSet.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction with sample data\n",
    "logist_model.predict([1.0,2.0,1.0,0.0,1.0,2.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
