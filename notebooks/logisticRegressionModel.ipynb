{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('prepare_data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 1000001\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "\n",
    "train_data = \"../datasets/oneMillTrain.csv\"\n",
    "\n",
    "custRDD = sc.textFile(train_data)\n",
    "\n",
    "print \"Train data size is {}\".format(custRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Customer_ID,Name,Gender,Address,Nationality,Account_Type,Age,Education,Employment,Salary,Employer_Stability,Consistency,Balance,Residential_Status,Service_Level',\n",
       " u'0,Diane Houston,Female,679 Morales Lane,Zimbabwean,Savings,0,0,2,1,1,1,2,1,1',\n",
       " u'1,Kristen Kelly,Male,5762 Robert Plaza Suite 861,Zimbabwean,Savings,2,1,2,0,1,1,2,1,2',\n",
       " u'2,Jeffrey Miller,Female,9865 James Tunnel,Zimbabwean,Current,2,1,0,1,1,1,1,1,1',\n",
       " u'3,Timothy Savage,Male,484 Rodriguez Viaduct,Zimbabwean,Current,1,0,1,0,0,1,2,1,0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the lines on the commas on Train data\n",
    "custRDD = custRDD.map(lambda line: line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Customer_ID',\n",
       "  u'Name',\n",
       "  u'Gender',\n",
       "  u'Address',\n",
       "  u'Nationality',\n",
       "  u'Account_Type',\n",
       "  u'Age',\n",
       "  u'Education',\n",
       "  u'Employment',\n",
       "  u'Salary',\n",
       "  u'Employer_Stability',\n",
       "  u'Consistency',\n",
       "  u'Balance',\n",
       "  u'Residential_Status',\n",
       "  u'Service_Level'],\n",
       " [u'0',\n",
       "  u'Diane Houston',\n",
       "  u'Female',\n",
       "  u'679 Morales Lane',\n",
       "  u'Zimbabwean',\n",
       "  u'Savings',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stripping the header from the RDD\n",
    "# passing a filter tells Spark to select all RDD member\n",
    "header = custRDD.first()\n",
    "custRDD = custRDD.filter(lambda line:line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'0',\n",
       "  u'Diane Houston',\n",
       "  u'Female',\n",
       "  u'679 Morales Lane',\n",
       "  u'Zimbabwean',\n",
       "  u'Savings',\n",
       "  u'0',\n",
       "  u'0',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'1'],\n",
       " [u'1',\n",
       "  u'Kristen Kelly',\n",
       "  u'Male',\n",
       "  u'5762 Robert Plaza Suite 861',\n",
       "  u'Zimbabwean',\n",
       "  u'Savings',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'0',\n",
       "  u'1',\n",
       "  u'1',\n",
       "  u'2',\n",
       "  u'1',\n",
       "  u'2']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mapping evry line from the RDD to a row in the DataFrame\n",
    "# piping the result with .toDF() to create the DataFrame\n",
    "# Gender = line[2], Account_Type = line[5], \n",
    "\n",
    "df = custRDD.map(lambda line: Row(Age = line[6], Education = line[7], Employment = line[8], Salary = line[9]\n",
    "                                  , Employer_Stability = line[10], Customer_Loyalty = line[11], Balance = line[12]\n",
    "                                  , Residential_Status = line[13], Service_Level = line[14])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Age=u'0', Balance=u'2', Customer_Loyalty=u'1', Education=u'0', Employer_Stability=u'1', Employment=u'2', Residential_Status=u'1', Salary=u'1', Service_Level=u'1'),\n",
       " Row(Age=u'2', Balance=u'2', Customer_Loyalty=u'1', Education=u'1', Employer_Stability=u'1', Employment=u'2', Residential_Status=u'1', Salary=u'0', Service_Level=u'2'),\n",
       " Row(Age=u'2', Balance=u'1', Customer_Loyalty=u'1', Education=u'1', Employer_Stability=u'1', Employment=u'0', Residential_Status=u'1', Salary=u'1', Service_Level=u'1'),\n",
       " Row(Age=u'1', Balance=u'2', Customer_Loyalty=u'1', Education=u'0', Employer_Stability=u'0', Employment=u'1', Residential_Status=u'1', Salary=u'0', Service_Level=u'0'),\n",
       " Row(Age=u'1', Balance=u'2', Customer_Loyalty=u'0', Education=u'0', Employer_Stability=u'1', Employment=u'1', Residential_Status=u'0', Salary=u'2', Service_Level=u'1')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|Service_Level|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|  0|      2|               1|        0|                 1|         2|                 1|     1|            1|\n",
      "|  2|      2|               1|        1|                 1|         2|                 1|     0|            2|\n",
      "|  2|      1|               1|        1|                 1|         0|                 1|     1|            1|\n",
      "|  1|      2|               1|        0|                 0|         1|                 1|     0|            0|\n",
      "|  1|      2|               0|        0|                 1|         1|                 0|     2|            1|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Customer_Loyalty</th>\n",
       "      <th>Education</th>\n",
       "      <th>Employer_Stability</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Residential_Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Service_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Balance Customer_Loyalty Education Employer_Stability Employment  \\\n",
       "0   0       2                1         0                  1          2   \n",
       "1   2       2                1         1                  1          2   \n",
       "2   2       1                1         1                  1          0   \n",
       "3   1       2                1         0                  0          1   \n",
       "4   1       2                0         0                  1          1   \n",
       "\n",
       "  Residential_Status Salary Service_Level  \n",
       "0                  1      1             1  \n",
       "1                  1      0             2  \n",
       "2                  1      1             1  \n",
       "3                  1      0             0  \n",
       "4                  0      2             1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_Age = df[df.Age == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|Service_Level|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "|  0|      2|               1|        0|                 1|         2|                 1|     1|            1|\n",
      "|  0|      1|               0|        0|                 1|         0|                 1|     1|            0|\n",
      "|  0|      1|               1|        0|                 1|         0|                 0|     0|            0|\n",
      "|  0|      0|               1|        0|                 0|         2|                 0|     0|            0|\n",
      "|  0|      1|               1|        1|                 0|         0|                 1|     1|            0|\n",
      "+---+-------+----------------+---------+------------------+----------+------------------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "favorite_Age.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Age|Balance|\n",
      "+---+-------+\n",
      "|  0|      2|\n",
      "|  2|      2|\n",
      "|  2|      1|\n",
      "|  1|      2|\n",
      "|  1|      2|\n",
      "|  2|      2|\n",
      "|  2|      1|\n",
      "|  0|      1|\n",
      "|  1|      1|\n",
      "|  0|      1|\n",
      "+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Age','Balance').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|Age| count|\n",
      "+---+------+\n",
      "|  0|333024|\n",
      "|  1|333891|\n",
      "|  2|333085|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|summary| Gender|Account_Type|               Age|          Balance|   Customer_Loyalty|        Education|Employer_Stability|        Employment| Residential_Status|            Salary|     Service_Level|\n",
      "+-------+-------+------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|1000000|     1000000|           1000000|          1000000|            1000000|          1000000|           1000000|           1000000|            1000000|           1000000|           1000000|\n",
      "|   mean|   null|        null|          1.000061|         0.999579|           0.499428|         0.500304|          0.499703|          0.999441|           0.499295|           1.00123|          0.495119|\n",
      "| stddev|   null|        null|0.8161554155849643|0.816237397454008|0.49999992281591665|0.500000157584135|0.5000001617911383|0.8163193945364456|0.49999975297469545|0.8164797325954647|0.6652462840118804|\n",
      "|    min| Female|     Current|                 0|                0|                  0|                0|                 0|                 0|                  0|                 0|                 0|\n",
      "|    max|   Male|     Savings|                 2|                2|                  1|                1|                 1|                 2|                  1|                 2|                 2|\n",
      "+-------+-------+------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Gender', 'Account_Type', 'Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability', 'Employment', 'Residential_Status', 'Salary', 'Service_Level']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression Model with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.select('Service_Level', 'Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability', 'Employment'\n",
    "              , 'Residential_Status', 'Salary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+\n",
      "|summary|     Service_Level|               Age|          Balance|   Customer_Loyalty|        Education|Employer_Stability|        Employment| Residential_Status|            Salary|\n",
      "+-------+------------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+\n",
      "|  count|           1000000|           1000000|          1000000|            1000000|          1000000|           1000000|           1000000|            1000000|           1000000|\n",
      "|   mean|          0.495119|          1.000061|         0.999579|           0.499428|         0.500304|          0.499703|          0.999441|           0.499295|           1.00123|\n",
      "| stddev|0.6652462840118804|0.8161554155849643|0.816237397454008|0.49999992281591665|0.500000157584135|0.5000001617911383|0.8163193945364456|0.49999975297469545|0.8164797325954647|\n",
      "|    min|                 0|                 0|                0|                  0|                0|                 0|                 0|                  0|                 0|\n",
      "|    max|                 2|                 2|                2|                  1|                1|                 1|                 2|                  1|                 2|\n",
      "+-------+------------------+------------------+-----------------+-------------------+-----------------+------------------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Service_Level', 'Age', 'Balance', 'Customer_Loyalty', 'Education', 'Employer_Stability'\n",
    "             , 'Employment', 'Residential_Status', 'Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "|Service_Level|Age|Balance|Customer_Loyalty|Education|Employer_Stability|Employment|Residential_Status|Salary|\n",
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "|            1|  0|      2|               1|        0|                 1|         2|                 1|     1|\n",
      "|            2|  2|      2|               1|        1|                 1|         2|                 1|     0|\n",
      "|            1|  2|      1|               1|        1|                 1|         0|                 1|     1|\n",
      "|            0|  1|      2|               1|        0|                 0|         1|                 1|     0|\n",
      "|            1|  1|      2|               0|        0|                 1|         1|                 0|     2|\n",
      "+-------------+---+-------+----------------+---------+------------------+----------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Points and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# created a tuple 'temp' of class/ output and a vector of predictors/ features\n",
    "# called rdd.map on the df to return an RDD of LabeledPoints\n",
    "# parsing the data\n",
    "\n",
    "temp = df.rdd.map(lambda line:LabeledPoint(line[0],[line[1:]]))\n",
    "#temp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the file as a parquet file with LabeledPoints\n",
    "\n",
    "# t0 = time()\n",
    "\n",
    "# temp.saveAsTextFile('../datasets/training')\n",
    "\n",
    "# tt = time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # load data\n",
    "# data = spark.read.format(\"csv\").load('../datasets/training/part-00000')\n",
    "\n",
    "# # making a test/ train split \n",
    "\n",
    "# splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "\n",
    "# trainingSet = splits[0]\n",
    "# testingSet = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # MultiClass Classification using a MultiLayer Perceptron Neural Network\n",
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# # Layers:\n",
    "# # input layers of size 8 (features), two intermediate (hidden) of size 9 and 8\n",
    "# # and output of size 3 (classes)\n",
    "\n",
    "# layers = [8, 9, 8, 3]\n",
    "\n",
    "\n",
    "# # NeuralNet trainer with parameters\n",
    "# trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "\n",
    "# # training the model\n",
    "# t0 = time()\n",
    "\n",
    "# model = trainer.fit(trainingSet)\n",
    "\n",
    "# # compute accuracy on test set\n",
    "# result = model.transform(testingSet)\n",
    "# predictionAndLabels = result.select('prediction', 'label')\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "\n",
    "\n",
    "# tt = time() - t0\n",
    "\n",
    "# print('MultiLayerPerceptron Classifier trained in {} seconds').format(round(tt, 3))\n",
    "# print ('Test set accuracy = ' + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet, testingSet = temp.randomSplit([0.8,0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 80.026 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# # building the model\n",
    "t0 = time()\n",
    "\n",
    "logist_model = LogisticRegressionWithLBFGS.train(trainingSet, iterations=10000, numClasses=3)\n",
    "\n",
    "\n",
    "tt = time() - t0\n",
    "\n",
    "print('Classifier trained in {} seconds').format(round(tt, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # evaluating the model on test data\n",
    "labelsAndPreds = testingSet.map(lambda p: (p.label, logist_model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.114383384498\n"
     ]
    }
   ],
   "source": [
    "# calculating error \n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(trainingSet.count())\n",
    "\n",
    "print('Training Error = ' + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 79.58 seconds. The test accuracy is 0.5414\n"
     ]
    }
   ],
   "source": [
    "# Testing the accuracy of prediction \n",
    "t0 = time()\n",
    "test_accuracy = labelsAndPreds.filter(lambda (v, p): v == p).count() / float(testingSet.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print('Prediction made in {} seconds. The test accuracy is {}').format(round(tt, 3), round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load the model\n",
    "lrModel = logist_model.predict(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the intercept coefficient\n",
    "logist_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0525, 0.0525, -0.2146, -0.2154, -0.2136, 0.0465, -0.2107, 0.0521, -0.0636, -0.0627, -0.421, -0.412, -0.4163, -0.064, -0.4094, -0.0608])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the weights of the variables\n",
    "logist_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [1.0,1.0,0.0,1.0,1.0,0.0,1.0,2.0]),\n",
       " LabeledPoint(0.0, [1.0,2.0,1.0,0.0,1.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,2.0,0.0,0.0,1.0,2.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,1.0,0.0,1.0,1.0,0.0,1.0]),\n",
       " LabeledPoint(2.0, [1.0,2.0,0.0,1.0,0.0,2.0,1.0,2.0]),\n",
       " LabeledPoint(2.0, [0.0,2.0,1.0,0.0,1.0,2.0,1.0,2.0]),\n",
       " LabeledPoint(0.0, [2.0,0.0,1.0,0.0,1.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [1.0,1.0,1.0,0.0,1.0,1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [2.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [2.0,1.0,0.0,1.0,0.0,1.0,0.0,1.0])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine testingSet and predicting\n",
    "testingSet.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction with sample data\n",
    "logist_model.predict([0.0,2.0,0.0,0.0,1.0,2.0,1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
